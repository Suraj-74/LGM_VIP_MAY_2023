{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c477dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# numpy is aliased as np\n",
    "import pandas as pd\n",
    "# pandas is aliased as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# pyplot is aliased as plt\n",
    "import tensorflow as tf\n",
    "# tensorflow is aliased as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c6e959",
   "metadata": {},
   "source": [
    "### load the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f17464",
   "metadata": {},
   "source": [
    "The MNIST dataset is a widely used dataset in machine learning and consists of a set of 60,000 training images and \n",
    "10,000 test images of handwritten digits from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53423aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38ce4abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "## checking the shapes of training and testing dataset\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8559338b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "# displayiing the data of x_train\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc2f3c",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b3541",
   "metadata": {},
   "source": [
    "1.Reshaping the input data which is work as a input for CNN<br>\n",
    "2.The original shape of x_train is (num_train_samples, 28, 28), where num_train_samples is the number of training samples,<br>     and 28 by 28 represents the dimensions of each image<br>\n",
    "3.CNN takes the input data with the shape,(num_samples, height, width, channels)..<br>\n",
    "4.Images are grayscale, so the channel value is set to 1<br>\n",
    "5.After reshaping the datatype of array will change to float32 which is common data type used in deep learning.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb1d8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce5989",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7074b0",
   "metadata": {},
   "source": [
    "The original pixel values in the MNIST dataset range from 0 to 255, where 0 represents black and 255 represents white.<br> Dividing the pixel values by 255 normalizes the data so that the values are scaled between 0 and 1.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "127d8fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.dtype)\n",
    "print(x_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66371bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fed068",
   "metadata": {},
   "source": [
    "### Build the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d087a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28435268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                77450     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,266\n",
      "Trainable params: 96,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed047cb5",
   "metadata": {},
   "source": [
    "This summary shows that the model has five layers:\n",
    "\n",
    "1. Conv2D: This layer performs convolutional operations on the input. It has 32 filters of size 3x3 and applies the<br> \n",
    "    ReLU activation function. The output shape is (None, 26, 26, 32), where None represents the batch size.<br>\n",
    "\n",
    "2. MaxPooling2D: This layer performs max pooling, which reduces the spatial dimensions of the input.<br> \n",
    "    It uses a 2x2 pooling window. The output shape is (None, 13, 13, 32), as the pooling operation reduces each spatial<br> \n",
    "    dimension by a factor of 2.<br>\n",
    "\n",
    "3. Conv2D: This layer is similar to the previous Conv2D layer but has 64 filters instead of 32.<br> \n",
    "    The output shape is (None, 11, 11, 64).<br>\n",
    "\n",
    "4. Flatten: This layer flattens the previous output, converting it from a 4D tensor to a 2D tensor.<br> \n",
    "    The output shape is (None, 7744), where 7744 is the result of multiplying the spatial dimensions.<br>\n",
    "\n",
    "5. Dense: This layer is a fully connected layer with 10 units and applies the ReLU activation function.<br> \n",
    "   It takes the flattened input and produces an output of shape (None, 10), where 10 represents the number of classes in<br>\n",
    "   the classification task.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3087d4",
   "metadata": {},
   "source": [
    "### plot a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "283626c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "#img = plt.imread('model.png')\n",
    "#plt.imshow(img)\n",
    "#plt.axis('off')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf93a1e",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6f4052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c761d35",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eee6afb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.1326 - accuracy: 0.9601 - val_loss: 0.0515 - val_accuracy: 0.9835\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.0334 - val_accuracy: 0.9888\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0328 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.0327 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0308 - val_accuracy: 0.9898\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.0430 - val_accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 55s 30ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0354 - val_accuracy: 0.9910\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0445 - val_accuracy: 0.9893\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0440 - val_accuracy: 0.9901\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0452 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203a926b6d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057c4d6",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51b96893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0452 - accuracy: 0.9903\n",
      "Test accuracy: 0.9902999997138977\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48093a12",
   "metadata": {},
   "source": [
    "### Displaying a Grayscale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc9e96a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[25]\n",
    "plt.imshow(np.squeeze(img) ,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd21c73",
   "metadata": {},
   "source": [
    "### Predicting the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17fc5730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "img= img.reshape(1, 28, 28, 1)\n",
    "a= model.predict([img])\n",
    "predicted_class = np.argmax(a)\n",
    "print(\"Predicted class: {}\".format(predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f93918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
